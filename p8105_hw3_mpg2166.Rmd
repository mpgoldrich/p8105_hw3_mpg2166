---
title: "P8105 Homework 3"
author: "Madison Goldrich mpg2166"
output: github_document
---

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .8,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

#### Load the data:

```{r}
data("instacart")

instacart =
  instacart |> 
  as_tibble()
```

#### Answer questions about the data: 

The `instacart` dataset is `r nrow(instacart)` rows by `r ncol(instacart)` columns. According to the description on the course website, "The dataset contains 1,384,617 observations of 131,209 unique users, where each row in the dataset is a product from an order." Some key variables include `product_id` which identifies the product, `order_id` which identifies the order in which the product was placed, `reordered` which identifies whether the product has been ordered by the user in the past, among others. In total there are `r instacart |> select(product_id) |>  distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |>  distinct() |>  count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

Below is a table summarizing the number of items ordered from each aisle. In total, there are 134 aisles, with fresh vegetables and fresh fruits having by far the most items ordered.

```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle, with aisles ordered by ascending number of items.

```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

The next table shows the three most popular items in `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, including the number of times each item is ordered.

```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |> 
  knitr::kable()
```

Table showing the mean hour of the day at which Pink Lady Apples and Coffe Ice Cream are ordered on each day of the week. Pink lady apples are generally purchased slightly earlier in the day than coffee ice cream, except on day 5.

```{r}
instacart |> 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> 
  group_by(product_name, order_dow) |> 
  summarize(mean_hour = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) |> 
  knitr::kable(digits = 2)
```


## Problem 2

#### Load and clean the data:

```{r}
data("brfss_smart2010")

brfss_smart2010 = 
  brfss_smart2010 |> 
  as_tibble() |> 
  janitor::clean_names() |> 
  rename(
    state = locationabbr, 
    location = locationdesc,
    resp_id = respid) |> 
  filter(
    topic == "Overall Health",
    response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |> 
  mutate(response = as_factor(response))
```

#### Answer questions about the data:

Below are 2 tables that show the states that were observed at 7 or more locations. The first table for the year 2002, with 6 states represented, and the second table for 2010 with 14 states.

```{r}
brfss_smart2010 |> 
  filter(year == 2002) |> 
  distinct(location, .keep_all = TRUE) |> 
  count(state) |> 
  filter(n >= 7) |> 
  knitr::kable()

brfss_smart2010 |> 
  filter(year == 2010) |> 
  distinct(location, .keep_all = TRUE) |> 
  count(state) |> 
  filter(n >= 7) |> 
  knitr::kable()
```

The below code onstructs a dataset `bfss_smart2010_excellent` that is limited to Excellent responses, and contains year, state, and a variable `mean_data_value` that averages the data_value across locations within a state. 

```{r}
brfss_smart2010_excellent =
  brfss_smart2010 |> 
  filter(response == "Excellent") |> 
  group_by(year, state) |> 
  summarize(
    mean_data_value = mean(data_value)
  )
```

This "spaghetti" plot shows the average value over time within a state.

```{r}
brfss_smart2010_excellent |> 
  ggplot(aes(x = year, y = mean_data_value, color = state)) +
  geom_line(aes(group = state)) +
  labs(title = "Spaghetti plot of mean data value over time by state")
```

The below plot shows the disribution of `data_value` by response level among locations in New York state in the years 2006 and 2010.

```{r}
brfss_smart2010 |> 
  filter(
    state == "NY",
    year %in% c(2006, 2010)) |> 
  ggplot(aes(x = data_value, fill = response)) +
  geom_density(alpha = .5) +
  facet_grid(. ~ year) +
  labs(title = "Distribution of data_value by response in NY state")
```


## Problem 3

#### Load, tidy, merge, and organize the datasets:

```{r}
nhanes_dem =
  read_csv("data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "Male",
      2 ~ "Female"),
    education = as_factor(case_match(
      education,
      1 ~ "Less than High School",
      2 ~ "High School equivalent",
      3 ~ "More than High School")))

nhanes_accel =
  read_csv("data/nhanes_accel.csv") |> 
  janitor::clean_names()

nhanes =
  full_join(nhanes_dem, nhanes_accel) |> 
  drop_na() |> 
  filter(age >= 21)
```


